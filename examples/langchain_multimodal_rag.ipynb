{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efe0f92-fdbb-4471-b74c-5bdaafed8102",
   "metadata": {},
   "source": [
    "# Multimodal RAG with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e78be0-9abe-4d1a-8aaa-61230b059792",
   "metadata": {},
   "source": [
    "This cookbook shows how to perform RAG on the table and text extraction output of the nv-ingest pdf extraction pipeline\n",
    "\n",
    "Using RAG on tables can present some challenges as raw table data doesn't always work well with semantic similarity search. To account for this, we will generate summaries of the table data to perform the similarity search on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487f1eb-eea8-46f1-9ab0-0fd3bea77bd5",
   "metadata": {},
   "source": [
    "\n",
    "First, let's load in the text and table json content from the extracted nv-ingest metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bcd6b2a-c832-4685-bd6e-53b60a107e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "text_data = json.loads(Path(\"./processed_docs/text/multimodal_test.pdf.metadata.json\").read_text())\n",
    "table_data = json.loads(Path(\"./processed_docs/structured/multimodal_test.pdf.metadata.json\").read_text())\n",
    "\n",
    "text_content = [doc[\"metadata\"][\"content\"] for doc in text_data]\n",
    "tables = [table[\"metadata\"][\"table_metadata\"][\"table_content\"] for table in table_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f637f1dc-1b25-4ecc-b540-4a669c57e3e1",
   "metadata": {},
   "source": [
    "Then, we'll split up our text content into smaller chunks while maintaining a large enough window to avoid losing context. However, we don't want to do this with our tables as doing so might break them up and corrupt them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d658a3-ce17-4515-ba26-b356e412a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "texts = text_splitter.split_documents([Document(text) for text in text_content])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22850a1-5915-4a09-a1e4-9f6669f0fd3b",
   "metadata": {},
   "source": [
    "Next, we'll create a chain that uses an llm to summarize our table or text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1c9595-e508-49b0-99fb-0c200fe4cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "os.environ[\"NVIDIA_API_KEY\"] = \"\"\n",
    "\n",
    "llm = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c639273e-e206-4d82-9896-d87bf0be1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\ \n",
    "Give a concise summary of the table or text. Table or text chunk: {element} \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85309220-53f6-4f59-a771-966dea97abbd",
   "metadata": {},
   "source": [
    "And then we'll apply that chain to each of our text and table chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8495a47-2490-435c-9dbb-216f501a0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d14f63-31b8-4d72-a029-a54328ff1c5b",
   "metadata": {},
   "source": [
    "Next, we'll create a multi vector retriever which allows us to store vectors both for the raw text and tables as well as the summaries we generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52539355-864b-4196-88b8-2d5493359346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=NVIDIAEmbeddings())\n",
    "\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f74fbb4-2448-4929-886f-657662d1d50b",
   "metadata": {},
   "source": [
    "Now, we can add the text and table as well as the text and table summaries to our retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff37bf98-9651-4d38-8c52-8a1875327010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
    "summary_texts = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(text_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
    "\n",
    "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
    "summary_tables = [\n",
    "    Document(page_content=s, metadata={id_key: table_ids[i]})\n",
    "    for i, s in enumerate(table_summaries)\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_tables)\n",
    "retriever.docstore.mset(list(zip(table_ids, tables)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87111b5-e5a8-45a0-9663-2ae6d9ea2ab6",
   "metadata": {},
   "source": [
    "Finally, we'll create an RAG chain that we can use to query our pdf in natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d16331bb-95dd-46d7-8b71-9d966a8ef3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Answer the question based only on the following context, which can include text and tables:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatNVIDIA(model=\"meta/llama-3.1-8b-instruct\")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b547a19a-9ada-4a40-a246-6d7bc4d24482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dog is chasing a squirrel in the front yard.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is the dog doing and where?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcfcb7-c6c6-4112-86c4-39e6975d325b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
